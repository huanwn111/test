{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task2 特征提取 \n",
    "1. 基本文本处理技能\n",
    "1.1 分词的概念（分词的正向最大、逆向最大、双向最大匹配法）；\n",
    "1.2 词、字符频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）\n",
    "2. 语言模型\n",
    "2.1 语言模型中unigram、bigram、trigram的概念；\n",
    "2.2 unigram、bigram频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）\n",
    "3. 文本矩阵化：要求采用词袋模型且是词级别的矩阵化\n",
    "步骤有：\n",
    "分词（可采用结巴分词来进行分词操作，其他库也可以）；去停用词；构造词表。\n",
    "每篇文档的向量化。\n",
    "4. 参考\n",
    "结巴分词介绍和使用：https://github.com/fxsjy/jieba\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. 基本文本处理技能\n",
    "1.1 分词的概念（分词的正向最大、逆向最大、双向最大匹配法）；\n",
    "\n",
    "分词是针对中文句子以词为单位的切分。\n",
    "\n",
    "正向最大匹配法:切分句子从左向右，依照最大匹配原则来切分。\n",
    "（判断最大匹配的标准：下一个词不在词表内；且也不是其它词的词辍）\n",
    "逆向最大匹配法:切分句子从右向左，依照最大匹配原则来切分。\n",
    "双向最大匹配法:结合使用上面两种（正向和逆向最大匹配法）\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 3), ('B', 2), ('C', 1), ('D', 1)]\n",
      "星期一 4\n",
      "星期二 1\n",
      "星期四 1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1.2 词、字符频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）\n",
    "'''\n",
    "from collections import Counter\n",
    "\n",
    "#统计字频\n",
    "wordList = ['A','B','A','C','D','B','A']\n",
    "\n",
    "counterNew = Counter(wordList)\n",
    "#统计每个词出现的次数，并打印\n",
    "print(counterNew.most_common(10))\n",
    "\n",
    "#统计词频\n",
    "wordCnList = ['星期一','星期二','星期一','星期四','星期一','星期一']\n",
    "cnt = Counter(wordCnList)\n",
    "for k,v in cnt.most_common(10):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. 语言模型\n",
    "2.1 语言模型中unigram、bigram、trigram的概念；\n",
    "\n",
    "unigram:一元分词，一个句子分词时以单个词为一个单元划分；\n",
    "bigram:二元分词，两词一组，即，分词时依据下一个词只和前面两个词相关，来组成一组进行划分；\n",
    "trigram:三元分词，三词一组，即，分词时依据下一个词和前面三个词相关，来组成一组进行划分；\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今 2\n",
      "天 4\n",
      "气 2\n",
      "晴 1\n",
      "朗 1\n",
      "不 2\n",
      "错 2\n",
      "， 1\n",
      "挺 1\n",
      "风 1\n",
      "和 1\n",
      "日 1\n",
      "丽 1\n",
      "的 1\n",
      "。 2\n",
      "我 1\n",
      "们 1\n",
      "下 1\n",
      "午 1\n",
      "没 1\n",
      "有 1\n",
      "课 1\n",
      "！ 1\n",
      "('今', '天') 2\n",
      "('天', '天') 2\n",
      "('天', '气') 2\n",
      "('气', '晴') 1\n",
      "('晴', '朗') 1\n",
      "('朗', '不') 1\n",
      "('不', '错') 2\n",
      "('错', '，') 1\n",
      "('，', '挺') 1\n",
      "('挺', '风') 1\n",
      "('风', '和') 1\n",
      "('和', '日') 1\n",
      "('日', '丽') 1\n",
      "('丽', '的') 1\n",
      "('的', '。') 1\n",
      "('。', '我') 1\n",
      "('我', '们') 1\n",
      "('们', '下') 1\n",
      "('下', '午') 1\n",
      "('午', '没') 1\n",
      "('没', '有') 1\n",
      "('有', '课') 1\n",
      "('课', '。') 1\n",
      "('。', '今') 1\n",
      "('气', '不') 1\n",
      "('错', '！') 1\n",
      "('今', '天', '天') 2\n",
      "('天', '天', '气') 2\n",
      "('天', '气', '晴') 1\n",
      "('气', '晴', '朗') 1\n",
      "('晴', '朗', '不') 1\n",
      "('朗', '不', '错') 1\n",
      "('不', '错', '，') 1\n",
      "('错', '，', '挺') 1\n",
      "('，', '挺', '风') 1\n",
      "('挺', '风', '和') 1\n",
      "('风', '和', '日') 1\n",
      "('和', '日', '丽') 1\n",
      "('日', '丽', '的') 1\n",
      "('丽', '的', '。') 1\n",
      "('的', '。', '我') 1\n",
      "('。', '我', '们') 1\n",
      "('我', '们', '下') 1\n",
      "('们', '下', '午') 1\n",
      "('下', '午', '没') 1\n",
      "('午', '没', '有') 1\n",
      "('没', '有', '课') 1\n",
      "('有', '课', '。') 1\n",
      "('课', '。', '今') 1\n",
      "('。', '今', '天') 1\n",
      "('天', '气', '不') 1\n",
      "('气', '不', '错') 1\n",
      "('不', '错', '！') 1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2.2 unigram、bigram频率统计；（可以使用Python中的collections.Counter模块，也可以自己寻找其他好用的库）\n",
    "【原理：如：bi二元的 遍历字符串，取第i个和第i+1个配组】\n",
    "'''\n",
    "\n",
    "#一元\n",
    "textGram = '今天天气晴朗不错，挺风和日丽的。我们下午没有课。今天天气不错！'\n",
    "uniCounter = Counter([textGram[i] for i in range(0,len(textGram))])\n",
    "print(\"\\n==一元分词===\")\n",
    "for k0,v0 in uniCounter.items():\n",
    "    print(k0,v0)\n",
    "#二元\n",
    "textGram = '今天天气晴朗不错，挺风和日丽的。我们下午没有课。今天天气不错！'\n",
    "biCounter = Counter([(textGram[i],textGram[i+1]) for i in range(0,len(textGram)-1)])\n",
    "print(\"\\n==二元分词===\")\n",
    "for k2,v2 in biCounter.items():\n",
    "    print(k2,v2)\n",
    "#三元\n",
    "triCounter = Counter([(textGram[i],textGram[i+1],textGram[i+2]) for i in range(0,len(textGram)-2)])\n",
    "print(\"\\n==三元分词===\")\n",
    "for k3,v3 in triCounter.items():\n",
    "    print(k3,v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==切分前==\n",
      "['今天天气不错，挺风和日丽的。\\n', '我们下午没有课。\\n', '我去上自习。\\n', '前面有个妹子在吃东西。']\n",
      "\n",
      "===切分后：全模式=====\n",
      "['今天', '今天天气', '天天', '天气', '不错', '', '', '挺', '风和日丽', '日丽', '的', '', '\\n', '我们', '下午', '没有', '课', '', '\\n', '我', '去', '上自', '自习', '', '\\n', '前面', '面有', '个', '妹子', '在', '吃', '东西', '', '']\n",
      "\n",
      "===切分后：精准模式=====\n",
      "['今天天气', '不错', '，', '挺', '风和日丽', '的', '。', '\\n', '我们', '下午', '没有', '课', '。', '\\n', '我', '去', '上', '自习', '。', '\\n', '前面', '有个', '妹子', '在', '吃', '东西', '。']\n",
      "\n",
      "===切分后：搜索引擎模式=====\n",
      "['今天', '天天', '天气', '今天天气', '不错', '，', '挺', '日丽', '风和日丽', '的', '。', '\\n', '我们', '下午', '没有', '课', '。', '\\n', '我', '去', '上', '自习', '。', '\\n', '前面', '有个', '妹子', '在', '吃', '东西', '。']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3. 文本矩阵化：要求采用词袋模型且是词级别的矩阵化\n",
    "步骤有：\n",
    "分词（可采用结巴分词来进行分词操作，其他库也可以）；去停用词；构造词表。\n",
    "每篇文档的向量化。\n",
    "4. 参考\n",
    "结巴分词介绍和使用：https://github.com/fxsjy/jieba\n",
    "'''\n",
    "#安装jieba. pip install jieba\n",
    "import jieba\n",
    "\n",
    "#text = ['自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。']\n",
    "text = ''\n",
    "#打开文本\n",
    "with open(r'cutText.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "print(\"==切分前==\")\n",
    "print(lines)\n",
    "for line in lines:\n",
    "    text  += line\n",
    "words = jieba.cut(text,cut_all=True)\n",
    "#第二参cut_all=True 全模式，以篇章角度，cut_all=False精准模式，词切的较细。\n",
    "#.cut_for_search()#搜索引擎模式，结合前两者。\n",
    "print(\"\\n===切分后：全模式=====\")\n",
    "wordsList = [w for w in words]\n",
    "print(wordsList)\n",
    "\n",
    "words2 = jieba.cut(text,cut_all=False)\n",
    "print(\"\\n===切分后：精准模式=====\")\n",
    "print([w2 for w2 in words2])\n",
    "\n",
    "words3 = jieba.cut_for_search(text)\n",
    "print(\"\\n===切分后：搜索引擎模式=====\")\n",
    "print([w3 for w3 in words3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==打印词袋==\n",
      "['今天', '今天天气', '天天', '天气', '不错', '', '挺', '风和日丽', '日丽', '的', '\\n', '我们', '下午', '没有', '课', '我', '去', '上自', '自习', '前面', '面有', '个', '妹子', '在', '吃', '东西']\n",
      "==打印初始0矩阵===\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今天</th>\n",
       "      <th>今天天气</th>\n",
       "      <th>天天</th>\n",
       "      <th>天气</th>\n",
       "      <th>不错</th>\n",
       "      <th></th>\n",
       "      <th>挺</th>\n",
       "      <th>风和日丽</th>\n",
       "      <th>日丽</th>\n",
       "      <th>的</th>\n",
       "      <th>...</th>\n",
       "      <th>去</th>\n",
       "      <th>上自</th>\n",
       "      <th>自习</th>\n",
       "      <th>前面</th>\n",
       "      <th>面有</th>\n",
       "      <th>个</th>\n",
       "      <th>妹子</th>\n",
       "      <th>在</th>\n",
       "      <th>吃</th>\n",
       "      <th>东西</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    今天  今天天气   天天   天气   不错         挺  风和日丽   日丽    的  ...    去   上自   自习  \\\n",
       "0  0.0   0.0  0.0  0.0  0.0  0.0  1.0   0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "1  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
       "3  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    前面   面有    个   妹子    在    吃   东西  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 用上面分好的词words做成词袋，做后续onehot编码的维度\n",
    "#print(wordsList)\n",
    "vocab = sorted(set(wordsList),key=wordsList.index)\n",
    "print(\"==打印词袋==\")\n",
    "print(vocab)\n",
    "\n",
    "#建初初0矩阵\n",
    "v = len(vocab)#不重复词的个数，即编码维度\n",
    "m = len(lines)#文本行数\n",
    "onehot = np.zeros((m,v))\n",
    "print(\"==打印初始0矩阵===\")\n",
    "print(onehotArr)\n",
    "\n",
    "#遍历文档行和词袋，反回词在词在中的位置，有则矩阵置\n",
    "for i,num in enumerate(lines):\n",
    "    for wd in num:\n",
    "        if wd in vocab:\n",
    "            #print(wd)\n",
    "            pos = vocab.index(wd)\n",
    "            onehot[i][pos] = 1\n",
    "        \n",
    "#转成DataFrame格式看下\n",
    "onehotDf = pd.DataFrame(onehot,columns = vocab)\n",
    "onehotDf.head()\n",
    "\n",
    "#【遗留问题：感觉结果不太对，待查】\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
