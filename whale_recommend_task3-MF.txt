4矩阵分解

4.1隐语义模型与矩阵分解

协同过滤算法的特点就是完全没有利用到物品本身或者是用户自身的属性， 仅仅利用了用户与物品的交互信息就可以实现推荐，解释性强， 直观。问题是是处理稀疏矩阵的能力比较弱。

所以为 了使得协同过滤更好处理稀疏矩阵问题， 增强泛化能力， 从协同过滤中衍生出矩阵分解模型(Matrix Factorization,MF)或者叫隐语义模型。

在协同过滤共现矩阵的基础上， 使用更稠密的隐向量表示用户和物品，
挖掘用户和物品的隐含兴趣和隐含特征。

4.2隐语义模型

核心思想是通过隐含特 征（latent factor）联系用户兴趣和物品（item）， 基于用户的行为找出潜在的主题和分类， 然后对item进行自动聚 类，划分到不同类别/主题(用户的兴趣)。

最早在文本领域被提出，用于找到文本的隐含语义。

例：

用户A和用户B两个用户在豆瓣的读书列表已知，，用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书， 而用户B的兴趣比较集中在数学和机器学习方面。 那么如何给A和B推荐图书。

协同过滤这样做：
基于用户UserCF:
要找到和他们看了同样书的其他用户（兴趣相似的用户），给他们推荐那些用户喜欢的其他书。

基于物品的ItmCF:
们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

是隐语义模型的话：
先通过一些角度（隐含特征）把用户兴趣和这些书划一下类， 当来了用户之后， 首先得到他的兴趣分类， 然后从这个分类中挑选他可能喜欢的书籍。（比如四角坐标系，用户落在哪个象限）

例2：

比如A喜欢带有小清新的， 吉他伴奏的， 王菲的歌曲，
如果一首歌同时满足是王菲唱 的， 并且是吉他伴奏的小清新， 
那么就可以将这首歌推荐给这个用户。

然后每个用户对不同因素的偏好程不同，每首歌的因素也不同。
所以就要搞两个矩阵（潜在因子），

一个是用户矩阵Q，表示每个用户对每种因素的喜欢程度权重。
比如张三 小清新0.6，伤感0.1 王菲0.7

另一个是音乐矩阵P,表示每首歌的因素占比权重
如音乐A 小表新0.9， 伤感0.4，王菲0

张三对音乐A的喜欢程度 = 张三对小清新的偏好 * 音乐A含有小清新的成分+ 张三对伤感的偏好 * 音乐A含有伤感的成分……

计算每个用户对应每首歌的评分，得到一个评分矩阵。

把用户的相似性和物品的相似性通过了一个叫做隐向量的方式进行关联起来了。（//像一个换算比例中间值一样。）

但实际上，这种隐含矩阵很难找，而且也不准，用户和音乐很多。
这时就用机器模型（矩阵分解模型）自动学习评分矩阵，分解矩阵，分解出像上在两个隐含矩阵。

即，把评分矩阵分解成Q和P两个矩阵乘积的形式（//有点统计里的共轭先验的分解之类的，分解法是数学里常见的解题方法），
再用这两个矩阵云预测（像上面音乐例子那种）某个新用户的评分，
根据预测评分做推荐。


4.3 矩阵分解算法的原理

可以结合协同过滤，先得到用户和物品的共现矩阵，
再通过分解共现矩阵来得到用户和物品的隐向量。


4.4矩阵分解算法的求解

特征值分解(EVD)或者奇异值分解(SVD），这两个基本不适用。

4.5BasicSVD

Funk-SVD 到 Latent Factor Model(LFM)。
思想： 把求解上面两个矩阵的参数问题转换成一个最优化问题， 可以通过训练集里面的观察值利用最小化来学习用户矩阵和物品矩阵。
求偏导，梯度下降……
加入正则惩罚项。
加入3项偏置 : 训练集中所有记录的评分的全局平均数；用户给出的所有评分的均值，物品收到的所有评分的均值;
//目地是，去除差异化，去量纲，加强泛化。

4.6编程实现

还是以Alice对第5个商品的评分预测为例：

	物品1	物品2	物品3	物品4	物品5
Alice 	5	3	4	4	？
用户1	3	1	2	3	3
用户2	4	3	4	3	5
用户3	3	3	1	5	4
用户4	1	5	5	2	1

来回忆一下ItemCF和UserCF对于这个问题的做法，
ItemCF的做法， 根据已有的用户打分计算物品之间的相似度， 得到物品的相似度矩阵， 根据这个相似度矩阵， 选择出前K个与物品5最相似的物品， 然后基于Alice对这K个物品的得分， 猜测Alice对物品5的得分， 有一个加权的计算公式。
UserCF的做法，是根据用户对其他物品的打分， 计算用户之间的相似度， 选择出与Alice最相近的K个用户， 然后基于那K个用户对物品5的打分计算出Alice对物品5的打分。

问题：矩阵稀疏问题。即，为两个相似用户不一定都对同一个物品打分，
Alice同时对两个相似物品打分的可能性也可能很小。

然后它没有考虑全局的物品或用户。

看SVD怎么解决？
1、首先， 它会先初始化用户矩阵P和物品矩阵Q， P的维度是 [users_num, F] , Q的维度是 [item_nums, F] ，
 这个F是隐向量的维度。 也就是把通过隐向量的方式把用户的兴趣和F的特点关联了起来。
注意初始化时 根据经验， 随机数需要和1/sqrt(F)成正比。
2、有了两个矩阵，根据用户已经打分的数据去更新参数， 这就是训练模型的过程。
具体做法：
遍历用户， 对于每个用户， 遍历它打分的物品， 这样就拿到了该用户用户隐向量和物品隐向量，
然后两者相乘加上偏置就是预测的评分， 这时候与真实评分有个差距， 根据上面的梯度下降就可以进行参数的更新。

训练完之后， 得到用户Alice和物品5的隐向量， 根据它，预测Alice对物品5的打分。

看代码：
#以下使用带有偏置项和正则项的那个SVD算法

class SVD():
    def __init__(self, rating_data, F=5, alpha=0.1, lmbda=0.1, max_iter=100):
        self.F = F # 这个表示隐向量的维度
        self.P = dict() # 用户矩阵P 大小是[users_num, F]
        self.Q = dict() # 物品矩阵Q 大小是[item_nums, F]
        self.bu = dict() # 用户偏差系数
        self.bi = dict() # 物品偏差系数
        self.mu = 0.0 # 全局偏差系数
        self.alpha = alpha # 学习率
        self.lmbda = lmbda # 正则项系数
        self.max_iter = max_iter # 最大迭代次数
        self.rating_data = rating_data # 评分矩阵

        # 初始化矩阵P和Q, 方法很多， 一般用随机数填充， 但随机数大小有讲究， 根据经验， 随机数需要和1/sqrt(F)成正比
        cnt = 0 # 统计总的打分数， 初始化mu用
        for user, items in self.rating_data.items():
            self.P[user] = [random.random() / math.sqrt(self.F) for x in range(0, F)]
            self.bu[user] = 0                
            cnt += len(items) 
            for item, rating in items.items():
                if item not in self.Q:
                    self.Q[item] = [random.random() / math.sqrt(self.F) for x in range(0, F)]
                    self.bi[item] = 0
        self.mu /= cnt

    # 有了矩阵之后， 就可以进行训练, 这里使用随机梯度下降的方式训练参数P和Q
    def train(self):
        for step in range(self.max_iter):
            for user, items in self.rating_data.items():
                for item, rui in items.items():
                    rhat_ui = self.predict(user, item) # 得到预测评分
                    # 计算误差
                    e_ui = rui - rhat_ui
                    self.bu[user] += self.alpha * (e_ui - self.lmbda * self.bu[user])
                    self.bi[item] += self.alpha * (e_ui - self.lmbda * self.bi[item])

                    # 随机梯度下降更新梯度
                    for k in range(0, self.F):
                        self.P[user][k] += self.alpha * (e_ui*self.Q[item][k] - self.lmbda * 
                        self.P[user][k])
                        self.Q[item][k] += self.alpha * (e_ui*self.P[user][k] - self.lmbda * 
                        self.Q[item][k])
            self.alpha *= 0.1 # 每次迭代步长要逐步缩小

    # 预测user对item的评分， 这里没有使用向量的形式
    def predict(self, user, item):
        return sum(self.P[user][f] * self.Q[item][f] for f in range(0, self.F)) + self.bu[user] + self.bi[item] + self.mu


#下面开始做 个数据集，训练预测。数据据用字典，不用pandas，因为稀疏，很多Nan。

# 定义数据集， 也就是那个Alice和用户的商品喜好表
def loadData():
    rating_data={1: {'A': 5, 'B': 3, 'C': 4, 'D': 4},
2: {'A': 3, 'B': 1, 'C': 2, 'D': 3, 'E': 3},
3: {'A': 4, 'B': 3, 'C': 4, 'D': 3, 'E': 5},
4: {'A': 3, 'B': 3, 'C': 1, 'D': 5, 'E': 4},
5: {'A': 1, 'B': 5, 'C': 5, 'D': 2, 'E': 1}
 }
    return rating_data

# 接下来就是训练和预测
rating_data = loadData()
basicsvd = SVD(rating_data, F=10)
basicsvd.train()
for item in ['E']:#第5个商品
     print(item, basicsvd.predict(1, item))

## 预测评分结果：
E 3.252210242858994
隐向量的维度， 训练次数和训练方式会影响结果

4.7课后思考
1. 矩阵分解算法后续有哪些改进呢?针对这些改进，是为了解决什么的问题呢？
RSVD，消除用户和物品打分偏差等
2. 矩阵分解的优缺点分析？
泛化能力强： 一定程度上解决了稀疏问题
空间复杂度低： 由于用户和物品都用隐向量的形式存放， 少了用户和物品相似度矩阵， 空间复杂度由n^2降到了（n+m）*f
更好的扩展性和灵活性：矩阵分解的最终产物是用户和物品隐向量， 这个深度学习的embedding思想不谋而合， 因此矩阵分解的结果非常便于与其他特征进行组合和拼接， 并可以与深度学习无缝结合。

不足：
依然是只用到了评分矩阵， 没有考虑到用户特征， 物品特征和上下文特征，很多有效信息没用到，缺乏用户历史行为的时候， 无法进行有效的推荐。

为了解决这个问题，后面出现逻辑回归模型及后续的因子分解机模型，
凭借其天然的融合不同特征的能力， 逐渐在推荐系统领域得到了更广泛的应用。



