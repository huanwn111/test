陆家嘴学堂
九 隐马尔科夫模型 HMM Hidden Makov Model
它是一个机器学习模型
在语言识别，自然语言处理，模式识别等领域得到广泛的应用
RNN LSTM这些崛起让HMM地位有所下降

用来描述一个含未知参数的马尔可夫过程。
难点是从可观察参数中确定该过程的隐含参数。


HMM不是处理离散的问题，而是 前后有关 连续的 比如温度 文本 时间序列的 
是 对时间序列（或者空间序列）考虑进去的一个模型

---
大纲：

概率计算 流程跑通了解用的相当于demo
参数估计 造
模型预测 用

中文分词算法实践

实践问题应如何中建模

执行一个模型 生成参数 A B PI 保存
再用另一个模型读这些参数 来切词

--
HMM上先给定一个字典再用HMM
字典中没有的是新词，它能发现新词

前后相继 相关联的链就是 马尔可夫模型 马尔可夫链 z1->z2->z3
这个链中的每一点又连着一些相关的独立观测点x1 x2 x3
x1 x2 x3之间间接相关了

我们能观测的是显现的，关系链是隐的，所以叫隐马尔可夫模型 HMM

用于标注问题、语音识别、NLP、生物信息、模式识别等领域 被实践证明是有效的算法

---

贝叶斯网络
z1->z2->z3 相关隐藏链
x1 x2 x3之间间接相关了

这个常用来建模解决实践中看似无关的问题。

上面这种有向无关图叫贝叶斯网络

把深度学习模型和贝叶斯网络结合是一个可能的方向
HMM是机器学习模型

---
HMM如何进行参数的描述


兰布达 = （A状态转移概率分布也就是链关系，B观测概率分布B，初始概率分布PI）

预测天气实例
天气间是有相关系的，假定只和相临的天有相关性（一阶HMM），比如前一天阴天，第二天可能下雨
二阶 三阶 和上下两代有关上下三代有关

天气x是显状态
但气压z是隐状态

描述：
用气压描述
分别两两组和的概率
见图
上面是A：隐状态条件转移概率矩阵

B：隐状态-》观测值（混淆矩阵）
气压与天气两两组合

PI:隐状态随机变量概率分布
z每一个可能出现的概率，比如南可能气压低的可能性大

例：
7天天气出现 s c r c s s 的概率


=============================


前向后向概率关系

。。。

---
走棋盘跳转

viterbi算法
所有路径求最大值

EM算法

求最优路径

---

算隐状态概率

----
===
例：

HMM+Viterbi实现统计分词

规则分词实现（正则匹配），
HMM+Viterbi实现统计分词（基于统计，建发射矩阵），jieba分词（分词封装库）

代码参考：



https://blog.csdn.net/aaalswaaa1/article/details/83745785










