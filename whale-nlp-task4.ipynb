{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText是一个快速文本分类算法，与基于神经网络的分类算法相比有两大优点：\n",
    "# 1、fastText在保持高精度的情况下加快了训练速度和测试速度\n",
    "# 2、fastText不需要预训练好的词向量，fastText会自己训练词向量\n",
    "# 3、fastText两个重要的优化：Hierarchical Softmax 分层softmax、N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastText模型架构和word2vec中的CBOW很相似， 不同之处是fastText预测标签而CBOW预测的是中间词，即模型架构类似但是模型的任务不同。\n",
    "#word2vec中提供了两种针对大规模多分类问题的优化手段， negative sampling 和hierarchical softmax。在优化中，negative sampling 只更新少量负面类，从而减轻了计算量。hierarchical softmax 将词库表示成前缀树，从树根到叶子的路径可以表示为一系列二分类器，一次多分类计算的复杂度从|V|降低到了树的高度\n",
    "#分层softmax(Hierarchical Softmax),思想是根据类别的频率构造霍夫曼树来代替标准softmax\n",
    "#n-gram是基于语言模型的算法,文本中词的前后词组字，扩充语料信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import fasttext\n",
    "from skllearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "'''\n",
    "分词\n",
    "去停用词\n",
    "把处理过后的词写入文本\n",
    "'''\n",
    "\n",
    "# 有监督的学习，训练分类器\n",
    "classifier = fasttext.supervised(filePath, \"classifier.model\")\n",
    "result = classifier.test(filePath)\n",
    "\n",
    "# 预测文档类别\n",
    "labels = classifier.predict(texts)\n",
    "\n",
    "# 预测类别+概率\n",
    "labelProb = classifier.predict_proba(texts)\n",
    "\n",
    "# 得到前k个类别\n",
    "labels = classifier.predict(texts, k=3)\n",
    "\n",
    "# 得到前k个类别+概率\n",
    "labelProb = classifier.predict_prob(texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold交叉验证\n",
    "#训练集测试集验证集数据混交多次分隔，数据少时可提高数据利用率\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    " \n",
    "train = pd.read_csv(\"../../Data/train.csv\")  # (6079, 41)\n",
    "test = pd.read_csv(\"../../Data/test.csv\")  # (476, 11)\n",
    " \n",
    "num_folds = 5\n",
    "gkf = GroupKFold(n_splits=num_folds).split(X=train.question_body, groups=train.question_body)  # train.question_body 用来获取总长度\n",
    "print(gkf)\n",
    " \n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):  # 五折交叉验证\n",
    "    print(\"fold:{}, 训练集长度:{}, 验证集长度：{}\".format(fold, len(train_idx), len(valid_idx)))\n",
    "    \n",
    "    train_data = train.iloc[train_idx]  # 按照行索引 获取数据\n",
    "    valid_data = train.iloc[valid_idx]  # 验证集\n",
    "    \n",
    "    print(len(train_data))\n",
    "    print(len(valid_data))\n",
    "    assert len(train_data) + len(valid_data) == len(train), (\"数据划分不正确\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
