任务二
逻辑回归算法梳理

1、逻辑回归与线性回归的联系与区别

联系：线性回归结果做出分类可以说算是逻辑回归。
逻辑回归是使用回归算法的分类方法。

区别：线性回归是为了连续值，比如预测y值，或通过迭代找到合适的参数代入模型，重新训练学习，预测y值。下次输入新的x值时可以使用模型来成功预测就说明模型是有效的。
      逻辑回归是预测分类问题，预测某个样本属于某类的概率。

2、 逻辑回归的原理
利用回归方法解决分类问题，
比如二分类，用到sigmoid函数预测一个0到1之间的值，得到概率，也就是预测函数；
构造损失函数；
用梯度下降法求最小值；


3、逻辑回归损失函数推导及优化
把sigmoid函数代入损失函数化解，引入最大似然函数概念，来最大化样本概率。
优化：为了计算方便，等式两边取对数，变成对数似然，使累乘变为累加，降低运算复杂度。
推导如下图：


4、 正则化与模型评估指标
回归中如果特征非常多，训练效果特别好，但在测试集效果不好，出现过拟合。
这时通常会引入正则惩罚项，L1，L2两种。

评估指标：

可以算召回率recall = TP/TP+FP
结合精度
用混淆矩阵处理
找到一个合适的参数


5、逻辑回归的优缺点

优点：
结果是0到1之间的概率
适用于连续性特征和也适用于类别性特征
容易使用和展示分析
训练起来高效，使用广泛

缺点：
不能用逻辑回归解决非线性问题
容易过拟合
依赖正确的数据表示（所以需要确定自变量时用较好）


6、样本不均衡问题解决办法

采用下采样和过采样处理；

下采样：是使样本一样少，随机选取样多样本中的一部分，使它与少量样本的分类一样数量相当，达到平衡。
缺点，数据变少，容易训练不足欠拟合。
可通过交叉验证充分利用样本。
调整分类界定阈值找到最优。

过采样：使样本一样多，给少量样本分类遵照特征不变的等欧式距离扩散方式补加数据，使它与多样本分类数据相当，达到平衡。

选择特征训练；

改变权重；

数据预处理；


7. sklearn参数

Sklearn 逻辑回归LogisticRegression()参数:
penalty:正则惩罚项，值为L1 L2,默认L2,
random_state：随机种子，设置为0则，保证每次随机生成的数据比例一致
C：正则强度，较小的值指定更强的正则化。默认为1



================================

参考资料
     1、西瓜书
     2、cs229吴恩达机器学习课程
     3、 李航统计学习
     4、谷歌搜索
